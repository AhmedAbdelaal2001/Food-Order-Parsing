{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "def load_pipeline(model_dir='models/pizza_model_fine_tuned', tokenizer_dir='models/pizza_tokenizer'):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
    "    ner_pipeline_instance = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"none\")\n",
    "    return ner_pipeline_instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_entities(ner_results):\n",
    "    \"\"\"\n",
    "    Applies custom post-processing to NER predictions, handling subword tokens and merging them correctly.\n",
    "    \n",
    "    Args:\n",
    "        ner_results (list of dict): Raw NER predictions from the pipeline.\n",
    "    \n",
    "    Returns:\n",
    "        list of str: Post-processed entity labels corresponding to each word in the sentence.\n",
    "    \"\"\"\n",
    "    predicted_labels = [entity['entity'] for entity in ner_results]\n",
    "    words = [entity['word'] for entity in ner_results]\n",
    "\n",
    "    connected_words = []\n",
    "    connected_labels = []\n",
    "    j = 0\n",
    "    while j < len(words):\n",
    "        if words[j].startswith('##'):\n",
    "            # Remove '##' and append to the previous word without any separator\n",
    "            if connected_words:\n",
    "                connected_words[-1] += words[j][2:]\n",
    "                # Update the label to the current token's label\n",
    "                connected_labels[-1] = predicted_labels[j]\n",
    "            else:\n",
    "                # Edge case: Subword at the beginning (rare)\n",
    "                connected_words.append(words[j][2:])\n",
    "                connected_labels.append(predicted_labels[j])\n",
    "            j += 1\n",
    "        elif words[j].startswith('#'):\n",
    "            # Handle single '#' if present (though typically '##' is used)\n",
    "            if connected_words:\n",
    "                connected_words[-1] += words[j][1:]\n",
    "                connected_labels[-1] = predicted_labels[j]\n",
    "            else:\n",
    "                # Edge case: Hashtag at the beginning\n",
    "                connected_words.append(words[j][1:])\n",
    "                connected_labels.append(predicted_labels[j])\n",
    "            j += 1\n",
    "        elif words[j] == \"'\":\n",
    "            # Handle apostrophes by merging with the next word\n",
    "            if connected_words and (j + 1) < len(words):\n",
    "                connected_words[-1] += (\"'\" + words[j + 1])\n",
    "                connected_labels.pop()  # Remove the last label as it's now part of the previous word\n",
    "                connected_labels.append(predicted_labels[j + 1])\n",
    "                j += 2\n",
    "            else:\n",
    "                # Edge case: Apostrophe at the beginning or no next word\n",
    "                connected_words.append(words[j])\n",
    "                connected_labels.append(predicted_labels[j])\n",
    "                j += 1\n",
    "        else:\n",
    "            # Regular word, add to the list\n",
    "            connected_words.append(words[j])\n",
    "            connected_labels.append(predicted_labels[j])\n",
    "            j += 1\n",
    "\n",
    "    # Custom label adjustment using a stack\n",
    "    stack = []\n",
    "    for j in range(len(connected_labels)):\n",
    "        label = connected_labels[j]\n",
    "        \n",
    "        # Handle 'PIZZA' labels\n",
    "        if label == 'PIZZA_BEGIN':\n",
    "            stack.append(j)\n",
    "        elif label == 'PIZZA_INTERMEDIATE':\n",
    "            if len(stack) == 0:\n",
    "                connected_labels[j] = 'PIZZA_BEGIN'\n",
    "                stack.append(j)\n",
    "        elif label == \"OTHER\":\n",
    "            if j > 0 and connected_labels[j-1] == \"PIZZA_INTERMEDIATE\":\n",
    "                stack.pop()\n",
    "        \n",
    "        # Handle 'DRINK' labels\n",
    "        if label == 'DRINK_BEGIN':\n",
    "            stack.append(j)\n",
    "        elif label == 'DRINK_INTERMEDIATE':\n",
    "            if len(stack) == 0:\n",
    "                connected_labels[j] = 'DRINK_BEGIN'\n",
    "                stack.append(j)\n",
    "        elif label == \"OTHER\":\n",
    "            if j > 0 and connected_labels[j-1] == \"DRINK_INTERMEDIATE\":\n",
    "                stack.pop()\n",
    "    \n",
    "    return connected_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence_detailed(sentence, ner_pipeline_instance):\n",
    "    \"\"\"\n",
    "    Processes a sentence and returns the post-processed NER labels along with words.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The input sentence to process.\n",
    "        ner_pipeline_instance (transformers.pipeline): The NER pipeline.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (word, label).\n",
    "    \"\"\"\n",
    "    # Run NER pipeline\n",
    "    ner_results = ner_pipeline_instance(sentence)\n",
    "    \n",
    "    # Extract words and labels\n",
    "    predicted_labels = [entity['entity'] for entity in ner_results]\n",
    "    words = [entity['word'] for entity in ner_results]\n",
    "\n",
    "    # Apply post-processing\n",
    "    processed_labels = postprocess_entities(ner_results)\n",
    "\n",
    "    # Now, we need to merge words that were combined during post-processing\n",
    "    connected_words = []\n",
    "    j = 0\n",
    "    while j < len(words):\n",
    "        if words[j].startswith('##'):\n",
    "            # Remove '##' and append to previous word\n",
    "            if connected_words:\n",
    "                connected_words[-1] += words[j][2:]\n",
    "            j += 1\n",
    "        elif words[j].startswith('#'):\n",
    "            # Remove '#' and append to previous word\n",
    "            if connected_words:\n",
    "                connected_words[-1] += words[j][1:]\n",
    "            j += 1\n",
    "        elif words[j] == \"'\":\n",
    "            # Merge apostrophe with the next word\n",
    "            if connected_words and (j + 1) < len(words):\n",
    "                connected_words[-1] += (\"'\" + words[j + 1])\n",
    "                j += 2\n",
    "            else:\n",
    "                connected_words.append(words[j])\n",
    "                j += 1\n",
    "        else:\n",
    "            connected_words.append(words[j])\n",
    "            j += 1\n",
    "\n",
    "    # Pair connected words with their processed labels\n",
    "    final_output = list(zip(connected_words, processed_labels))\n",
    "    \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postprocessed_labels(sentence, ner_pipeline_instance):\n",
    "    \"\"\"\n",
    "    Processes an input sentence and returns the post-processed NER labels.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence to process.\n",
    "        ner_pipeline_instance (transformers.pipeline): The NER pipeline.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of post-processed labels corresponding to each word in the sentence.\n",
    "    \"\"\"\n",
    "    # Get detailed labels (word, label pairs)\n",
    "    detailed_labels = process_sentence_detailed(sentence, ner_pipeline_instance)\n",
    "    \n",
    "    # Extract labels only\n",
    "    labels = [label for word, label in detailed_labels]\n",
    "    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_orders(sentence, ner_pipeline_instance):\n",
    "    \"\"\"\n",
    "    Segments the input sentence into pizza and drink orders based on NER labels.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The input sentence to process.\n",
    "        ner_pipeline_instance (transformers.pipeline): The NER pipeline.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Two lists containing pizza orders and drink orders respectively.\n",
    "    \"\"\"\n",
    "    # Get detailed labels\n",
    "    detailed_labels = process_sentence_detailed(sentence, ner_pipeline_instance)\n",
    "    \n",
    "    orders = []\n",
    "    \n",
    "    current_pizza = []\n",
    "    current_drink = []\n",
    "    \n",
    "    in_pizza = False\n",
    "    in_drink = False\n",
    "    \n",
    "    for word, label in detailed_labels:\n",
    "        # Handle Pizza Orders\n",
    "        if label == 'PIZZA_BEGIN':\n",
    "            if in_pizza and current_pizza:\n",
    "                orders.append((' '.join(current_pizza), True))\n",
    "                current_pizza = []\n",
    "            in_pizza = True\n",
    "            current_pizza.append(word)\n",
    "        elif label == 'PIZZA_INTERMEDIATE' and in_pizza:\n",
    "            current_pizza.append(word)\n",
    "        else:\n",
    "            if in_pizza and current_pizza:\n",
    "                orders.append((' '.join(current_pizza), True))\n",
    "                current_pizza = []\n",
    "            in_pizza = False\n",
    "        \n",
    "        # Handle Drink Orders\n",
    "        if label == 'DRINK_BEGIN':\n",
    "            if in_drink and current_drink:\n",
    "                orders.append((' '.join(current_drink), False))\n",
    "                current_drink = []\n",
    "            in_drink = True\n",
    "            current_drink.append(word)\n",
    "        elif label == 'DRINK_INTERMEDIATE' and in_drink:\n",
    "            current_drink.append(word)\n",
    "        else:\n",
    "            if in_drink and current_drink:\n",
    "                orders.append((' '.join(current_drink), False))\n",
    "                current_drink = []\n",
    "            in_drink = False\n",
    "    \n",
    "    # Append any remaining orders after the loop\n",
    "    if in_pizza and current_pizza:\n",
    "        orders.append((' '.join(current_pizza), True))\n",
    "    if in_drink and current_drink:\n",
    "        orders.append((' '.join(current_drink), False))\n",
    "    \n",
    "    return orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_top_decoupled(sentence, labels, is_pizza_order):\n",
    "    output_sentence = \"\"\n",
    "    tokens = sentence.split()\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if labels[i] == \"OTHER\": \n",
    "            i += 1\n",
    "            continue\n",
    "        if '-' in labels[i]:\n",
    "            index = labels[i].rfind('-')\n",
    "            parent_identifier = labels[i][:index]\n",
    "            sub_tokens = []\n",
    "            sub_labels = []\n",
    "            while i < len(tokens) and labels[i][:index] == parent_identifier:\n",
    "                sub_tokens.append(tokens[i])\n",
    "                sub_labels.append(labels[i][index+1:])\n",
    "                i += 1\n",
    "                continue\n",
    "            nested_part_string = generate_top_decoupled(' '.join(sub_tokens), sub_labels, -1)\n",
    "            output_sentence += ('(' + parent_identifier + ' ' + nested_part_string + ') ')\n",
    "            continue\n",
    "\n",
    "        curr_label = labels[i]\n",
    "        curr_element = []\n",
    "        j = 0\n",
    "        while i+j < len(labels) and labels[i+j] == curr_label:\n",
    "            curr_element.append(tokens[i+j])\n",
    "            j += 1\n",
    "        i = i + j - 1\n",
    "        j = 0\n",
    "        curr_element_string = ' '.join(curr_element)\n",
    "        output_sentence += ('(' + curr_label + ' ' + curr_element_string + ' ) ')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    if is_pizza_order == -1:\n",
    "        return output_sentence\n",
    "    \n",
    "    if is_pizza_order == 0: \n",
    "        identifier = '(PIZZAORDER '\n",
    "    else:\n",
    "        identifier = '(DRINKORDER '\n",
    "\n",
    "    output_sentence = identifier + output_sentence + ')'\n",
    "    return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Order: i need a medium ham and pineapple pizza and a small iced tea\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "Top Decoupled: (PIZZAORDER (NUMBER a ) (SIZE medium ) (TOPPING ham ) (TOPPING pineapple ) ) (DRINKORDER (NUMBER a ) (SIZE small ) (DRINKTYPE iced tea ) )\n"
     ]
    }
   ],
   "source": [
    "isa = load_pipeline(model_dir='models/ISA_model', tokenizer_dir='models/pizza_tokenizer')\n",
    "parser = load_pipeline(model_dir='models/order_parser', tokenizer_dir='models/pizza_tokenizer')\n",
    "sentence = \"i need a medium ham and pineapple pizza and a small iced tea\"\n",
    "\n",
    "print(\"Input Order: \" + sentence)\n",
    "print(\"\\n----------------------------------------------------\\n\")\n",
    "\n",
    "# Segment orders\n",
    "orders = segment_orders(sentence, isa)\n",
    "top_decoupled = ''\n",
    "for order_pair in orders:\n",
    "    order = order_pair[0]\n",
    "    is_pizza = order_pair[1]\n",
    "    labels = get_postprocessed_labels(order, parser)\n",
    "\n",
    "    if is_pizza: id = 0\n",
    "    else: id = 1\n",
    "\n",
    "    top_decoupled += (generate_top_decoupled(order, labels, id) + ' ')\n",
    "\n",
    "print(\"Top Decoupled: \" + top_decoupled[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TOP: (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING bbq pulled pork ) ) )\n",
      "Generated TOP-DECOUPLED: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING bbq pulled pork ) ) )\n",
      "Expected TOP-DECOUPLED: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING bbq pulled pork ) ) )\n",
      "Match: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Represents a node in the labeled hierarchical structure.\n",
    "    Each node has a label and can have child nodes or text.\n",
    "    \"\"\"\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        self.children = []  # List of child Node instances\n",
    "        self.text = None    # Text content if the node is a leaf\n",
    "\n",
    "    def to_string(self):\n",
    "        \"\"\"\n",
    "        Recursively converts the node and its children back into the bracketed string format.\n",
    "        \"\"\"\n",
    "        if self.text and not self.children:\n",
    "            # Leaf node with text\n",
    "            return f\"({self.label} {self.text} )\"\n",
    "        elif self.children:\n",
    "            # Node with child labels\n",
    "            children_str = ' '.join(child.to_string() for child in self.children)\n",
    "            return f\"({self.label} {children_str} )\"\n",
    "        else:\n",
    "            # Node without children or text\n",
    "            return f\"({self.label} )\"\n",
    "\n",
    "def tokenize(top_string):\n",
    "    \"\"\"\n",
    "    Splits the TOP string into tokens: '(', ')', and words.\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\(|\\)|[^\\s()]+', top_string)\n",
    "\n",
    "def parse(tokens, index):\n",
    "    \"\"\"\n",
    "    Recursively parses tokens to build the hierarchical structure.\n",
    "    \n",
    "    Parameters:\n",
    "    - tokens: List of tokens from the TOP string.\n",
    "    - index: Current position in the token list.\n",
    "    \n",
    "    Returns:\n",
    "    - node: The parsed Node object.\n",
    "    - index: Updated position after parsing.\n",
    "    \"\"\"\n",
    "    if tokens[index] != '(':\n",
    "        # Not a label, skip\n",
    "        return None, index\n",
    "\n",
    "    label = tokens[index + 1]\n",
    "    node = Node(label)\n",
    "    index += 2  # Move past '(' and label\n",
    "\n",
    "    texts = []        # Collect text tokens\n",
    "    has_children = False  # Flag to indicate presence of child labels\n",
    "\n",
    "    while index < len(tokens):\n",
    "        token = tokens[index]\n",
    "        if token == '(':\n",
    "            # Found a child label; parse it recursively\n",
    "            child, index = parse(tokens, index)\n",
    "            if child:\n",
    "                node.children.append(child)\n",
    "                has_children = True\n",
    "        elif token == ')':\n",
    "            index += 1  # Move past ')'\n",
    "            if not has_children and texts:\n",
    "                # If no child labels, set the text content\n",
    "                node.text = ' '.join(texts)\n",
    "            return node, index\n",
    "        else:\n",
    "            # Text token\n",
    "            if not has_children:\n",
    "                # Only collect text if no child labels have been found\n",
    "                texts.append(token)\n",
    "            index += 1\n",
    "\n",
    "    return node, index\n",
    "\n",
    "def generate_top_decoupled_from_top(top_string):\n",
    "    \"\"\"\n",
    "    Converts a TOP string into a TOP-DECOUPLED string by removing redundant tokens.\n",
    "    \n",
    "    Parameters:\n",
    "    - top_string (str): The input TOP string.\n",
    "    \n",
    "    Returns:\n",
    "    - decoupled_str (str): The resulting TOP-DECOUPLED string.\n",
    "    \"\"\"\n",
    "    tokens = tokenize(top_string)\n",
    "    node, _ = parse(tokens, 0)\n",
    "    if node:\n",
    "        return node.to_string()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "top = \"(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING bbq pulled pork ) ) )\"\n",
    "expected = \"(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING bbq pulled pork ) ) )\"\n",
    "decoupled = generate_top_decoupled_from_top(top)\n",
    "print(f\"Original TOP: {top}\")\n",
    "print(f\"Generated TOP-DECOUPLED: {decoupled}\")\n",
    "print(f\"Expected TOP-DECOUPLED: {expected}\")\n",
    "print(f\"Match: {decoupled == expected}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Count: 4\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE medium ) (TOPPING sausage ) (TOPPING mushrooms ) (NOT (TOPPING ham ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE medium ) (TOPPING sausage mushrooms ) (NOT (TOPPING ham ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 5\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER one ) (TOPPING sausage ) (TOPPING olives ) (TOPPING pineapple ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER one ) (TOPPING sausage olives ) (TOPPING pineapple ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 5\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE small ) (TOPPING mushrooms ) (TOPPING bacon ) (TOPPING pepperoni ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE small ) (TOPPING mushrooms ) (TOPPING bacon pepperoni ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 7\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING sausage ) (TOPPING olives ) (TOPPING pineapple ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING sausage olives ) (TOPPING pineapple ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 11\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING ham ) (TOPPING chicken ) (TOPPING pineapple ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING ham chicken ) (TOPPING pineapple ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 11\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE medium ) (TOPPING pepperoni ) ) (PIZZAORDER (NUMBER one ) (SIZE small ) (TOPPING onions ) (TOPPING black olives ) (TOPPING peppers ) ) (DRINKORDER (NUMBER three ) (SIZE large ) (DRINKTYPE sprites ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE medium ) (TOPPING pepperoni ) ) (PIZZAORDER (NUMBER one ) (SIZE small ) (TOPPING onions black olives ) (TOPPING peppers ) ) (DRINKORDER (NUMBER three ) (SIZE large ) (DRINKTYPE sprites ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 13\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING pepperoni ) (TOPPING sausage ) (TOPPING black olives ) (TOPPING onions ) (TOPPING anchovies ) ) (DRINKORDER (NUMBER three ) (SIZE large ) (DRINKTYPE cokes ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING pepperoni sausage black olives onions ) (TOPPING anchovies ) ) (DRINKORDER (NUMBER three ) (SIZE large ) (DRINKTYPE cokes ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 14\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE small ) (TOPPING sausage ) (TOPPING pesto ) (NOT (TOPPING pepperoni ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE small ) (TOPPING sausage pesto ) (NOT (TOPPING pepperoni ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 14\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE medium ) (TOPPING bacon ) (TOPPING pesto ) (NOT (TOPPING sausage ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE medium ) (TOPPING bacon pesto ) (NOT (TOPPING sausage ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 15\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE large ) (TOPPING pepperoni ) (TOPPING sausage ) (TOPPING anchovies ) (TOPPING onions ) ) (DRINKORDER (NUMBER two ) (SIZE large ) (DRINKTYPE cokes ) ) (DRINKORDER (NUMBER one ) (SIZE large ) (DRINKTYPE sprite ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE large ) (TOPPING pepperoni sausage anchovies ) (TOPPING onions ) ) (DRINKORDER (NUMBER two ) (SIZE large ) (DRINKTYPE cokes ) ) (DRINKORDER (NUMBER one ) (SIZE large ) (DRINKTYPE sprite ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 15\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING beef ) (TOPPING bacon ) (TOPPING ham ) (TOPPING onions ) (TOPPING black olives ) ) (DRINKORDER (NUMBER three ) (SIZE large ) (DRINKTYPE diet cokes ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING beef bacon ham onions ) (TOPPING black olives ) ) (DRINKORDER (NUMBER three ) (SIZE large ) (DRINKTYPE diet cokes ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 18\n",
      "True Output: (ORDER (PIZZAORDER (SIZE medium ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) (TOPPING sausage ) (TOPPING mushroom ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (SIZE medium ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) (TOPPING sausage mushroom ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 18\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE small ) (TOPPING pesto ) (TOPPING bacon ) (NOT (TOPPING onions ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE small ) (TOPPING pesto bacon ) (NOT (TOPPING onions ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 19\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (TOPPING peppers ) (TOPPING bacon ) (TOPPING pesto ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (TOPPING peppers ) (TOPPING bacon pesto ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 21\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE large ) (STYLE everything ) ) (PIZZAORDER (NUMBER two ) (SIZE large ) (TOPPING mushrooms ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) ) (DRINKORDER (NUMBER six ) (SIZE large ) (DRINKTYPE cokes ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE large ) ) (PIZZAORDER (NUMBER two ) (SIZE large ) (TOPPING mushrooms ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) ) (DRINKORDER (NUMBER six ) (SIZE large ) (DRINKTYPE cokes ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 21\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING pineapple ) (TOPPING ham ) (NOT (TOPPING peppers ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING pineapple ham ) (NOT (TOPPING peppers ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 26\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING mushroom ) (TOPPING pepperoni ) (TOPPING banana pepper ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING mushroom pepperoni ) (TOPPING banana pepper ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 30\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (TOPPING mushrooms ) (TOPPING pesto ) (SIZE medium ) (NOT (TOPPING onions ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (TOPPING mushrooms pesto ) (SIZE medium ) (NOT (TOPPING onions ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 33\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE small ) (TOPPING bacon ) (TOPPING mushroom ) (NOT (TOPPING pineapple ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER one ) (SIZE small ) (TOPPING bacon mushroom ) (NOT (TOPPING pineapple ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 33\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER an ) (TOPPING onion ) (TOPPING ham ) (TOPPING tuna ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER an ) (TOPPING onion ham ) (TOPPING tuna ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 33\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING bacon ) (TOPPING sausage ) (TOPPING mushrooms ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING bacon sausage ) (TOPPING mushrooms ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 33\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING tuna ) (TOPPING olives ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING tuna olives ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 36\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE medium ) (TOPPING chicken ) (TOPPING sausage ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE medium ) (TOPPING chicken sausage ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 42\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE small ) (STYLE vegan ) ) (PIZZAORDER (NUMBER one ) (SIZE large ) (STYLE vegetarian ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE small ) (TOPPING vegan ) ) (PIZZAORDER (NUMBER one ) (SIZE large ) (STYLE vegetarian ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 43\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE large ) (TOPPING chicken ) (TOPPING mushroom ) (NOT (TOPPING olives ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE large ) (TOPPING chicken mushroom ) (NOT (TOPPING olives ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 47\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING pesto ) (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) (NOT (TOPPING tuna ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING pesto ) (COMPLEX_TOPPING (TOPPING cheese ) ) (NOT (TOPPING tuna ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 48\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER one ) (TOPPING bacon ) (TOPPING olives ) (NOT (TOPPING pesto ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER one ) (TOPPING bacon olives ) (NOT (TOPPING pesto ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 50\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING ham ) (TOPPING pesto ) (TOPPING mushrooms ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING ham pesto ) (TOPPING mushrooms ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 55\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING pineapple ) (TOPPING sausage ) (NOT (TOPPING peppers ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING pineapple sausage ) (NOT (TOPPING peppers ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 57\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE small ) (TOPPING pepperoni ) (TOPPING sausage ) (NOT (TOPPING olives ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE small ) (TOPPING pepperoni sausage ) (NOT (TOPPING olives ) ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 60\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING bacon ) (TOPPING mushroom ) (TOPPING sausage ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (TOPPING bacon mushroom ) (TOPPING sausage ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 64\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE large ) (STYLE deep dish ) (STYLE meat lovers ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE large ) (STYLE deep dish meat lovers ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Correct Count: 67\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE small ) (STYLE thin crust ) (TOPPING pesto ) (TOPPING onions ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE small ) (STYLE thin crust ) (TOPPING pesto onions ) ) )\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "correct_count = 0\n",
    "i = 0\n",
    "with open(\"dataset/PIZZA_test.json\", 'r') as infile:\n",
    "    for line in infile:\n",
    "        if i == 100: break\n",
    "        instance = json.loads(line)\n",
    "        input_sentence = instance.get(f\"test.SRC\", \"\")\n",
    "        top = instance.get(f\"test.TOP\", \"\")\n",
    "        true_top_decoupled = generate_top_decoupled_from_top(top)\n",
    "\n",
    "\n",
    "        orders = segment_orders(input_sentence, isa)\n",
    "        top_decoupled = ''\n",
    "        for order_pair in orders:\n",
    "            order = order_pair[0]\n",
    "            is_pizza = order_pair[1]\n",
    "            labels = get_postprocessed_labels(order, parser)\n",
    "\n",
    "            if is_pizza: id = 0\n",
    "            else: id = 1\n",
    "\n",
    "            top_decoupled += (generate_top_decoupled(order, labels, id) + ' ')\n",
    "        \n",
    "        top_decoupled = \"(ORDER \" + top_decoupled + ')'\n",
    "\n",
    "        if top_decoupled == true_top_decoupled: correct_count += 1\n",
    "        else:\n",
    "            print(f\"Correct Count: {correct_count}\")\n",
    "            print(\"True Output: \" + true_top_decoupled)\n",
    "            print(\"Predicted Output: \" + top_decoupled)\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

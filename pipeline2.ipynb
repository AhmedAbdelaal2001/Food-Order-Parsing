{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to import all of the necessary dependencies for your model to operate. Both pipeline 1 and 2 should include the following:\n",
    "\n",
    "1. utils.py\n",
    "2. Path to the child model class\n",
    "3. Any extra dependencies unrelated to the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "# (TODO) Rest of the imports (Anyone)\n",
    "from BiLSTM_Module2 import BiLSTM_Module2\n",
    "from LSTM.LSTM import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, store the path to the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) Adjust the path to the test set if needed (Anyone)\n",
    "# Note: This is the ORIGINAL test data, the one that contains test.SRC, test.TOP, etc..\n",
    "# If you don't have it, download it from the repo at https://github.com/amazon-science/pizza-semantic-parsing-dataset/tree/main/data\n",
    "test_data_dir = \"dataset/PIZZA_test.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load modules 1 and 2 using the classes you created. You can change the constructor to take any parameters; just make sure that you classes contain an implementation of the \"predict_labels\" method and takes no extra parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) Instantiate module 1 (Hany and Marwan)\n",
    "model_path = \"LSTM\\lstm.keras\"\n",
    "word2vec_path = \"LSTM\\word2vec\\word2vec_model.kv\"\n",
    "module1 = LSTM(model_path, word2vec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) Instantiate module 2 (Tyson)\n",
    "model_path=\"sequence_labelling_final_model.keras\"\n",
    "module2 = BiLSTM_Module2(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! The rest of the code should not be changed. Just run all :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"i would like to try one large chicken and mushroom pizza with no extra cheese please\"\n",
    "\n",
    "print(\"Input Order: \" + sentence)\n",
    "\n",
    "# Segment orders\n",
    "isa_words, isa_labels = module1.predict_labels(sentence)\n",
    "orders = segment_orders(isa_words, isa_labels)\n",
    "top_decoupled = ''\n",
    "for order_pair in orders:\n",
    "    order = order_pair[0]\n",
    "    is_pizza = order_pair[1]\n",
    "    parser_words, parser_labels = module2.predict_labels(order)\n",
    "\n",
    "    if is_pizza: id = 0\n",
    "    else: id = 1\n",
    "\n",
    "    top_decoupled += (generate_top_decoupled(order, parser_labels, id) + ' ')\n",
    "\n",
    "print(\"Top Decoupled: \" + top_decoupled[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "correct_count = 0\n",
    "i = 0\n",
    "with open(test_data_dir, 'r') as infile:\n",
    "    for line in infile:\n",
    "        instance = json.loads(line)\n",
    "        input_sentence = instance.get(f\"test.SRC\", \"\")\n",
    "        top = instance.get(f\"test.TOP\", \"\")\n",
    "        true_top_decoupled = generate_top_decoupled_from_top(top)\n",
    "\n",
    "        isa_words, isa_labels = module1.predict_labels(input_sentence)\n",
    "        orders = segment_orders(isa_words, isa_labels)\n",
    "        top_decoupled = ''\n",
    "        for order_pair in orders:\n",
    "            order = order_pair[0]\n",
    "            is_pizza = order_pair[1]\n",
    "            parser_words, parser_labels = module2.predict_labels(order)\n",
    "\n",
    "            if is_pizza: id = 0\n",
    "            else: id = 1\n",
    "\n",
    "            top_decoupled += (generate_top_decoupled(order, parser_labels, id) + ' ')\n",
    "        \n",
    "        top_decoupled = \"(ORDER \" + top_decoupled + ')'\n",
    "\n",
    "        if top_decoupled == true_top_decoupled: correct_count += 1\n",
    "        else:\n",
    "            print(f\"Row Index: {i}\")\n",
    "            print(\"Input Sentence: \" + input_sentence)\n",
    "            print(\"True Output: \" + true_top_decoupled)\n",
    "            print(\"Predicted Output: \" + top_decoupled)\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "        \n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count / i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

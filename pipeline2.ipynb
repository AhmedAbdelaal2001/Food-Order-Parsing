{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to import all of the necessary dependencies for your model to operate. Both pipeline 1 and 2 should include the following:\n",
    "\n",
    "1. utils.py\n",
    "2. Path to the child model class\n",
    "3. Any extra dependencies unrelated to the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'FeaturesExtractor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# (TODO) Rest of the imports (Anyone)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBiLSTM_Module2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BiLSTM_Module2\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mLSTM\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLSTM\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM\n",
      "File \u001b[1;32mc:\\Users\\Marwan\\Desktop\\College\\5_1\\NLP\\Food-Order-Parsing\\LSTM\\LSTM.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFeaturesExtractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeaturesExtractor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'FeaturesExtractor'"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "# (TODO) Rest of the imports (Anyone)\n",
    "from BiLSTM_Module2 import BiLSTM_Module2\n",
    "from LSTM.LSTM import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, store the path to the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) Adjust the path to the test set if needed (Anyone)\n",
    "# Note: This is the ORIGINAL test data, the one that contains test.SRC, test.TOP, etc..\n",
    "# If you don't have it, download it from the repo at https://github.com/amazon-science/pizza-semantic-parsing-dataset/tree/main/data\n",
    "test_data_dir = \"dataset/PIZZA_test.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load modules 1 and 2 using the classes you created. You can change the constructor to take any parameters; just make sure that you classes contain an implementation of the \"predict_labels\" method and takes no extra parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) Instantiate module 1 (Hany and Marwan)\n",
    "module1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) Instantiate module 2 (Tyson)\n",
    "model_path=\"sequence_labelling_final_model.keras\"\n",
    "module2 = BiLSTM_Module2(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! The rest of the code should not be changed. Just run all :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Order: i would like to try one large chicken and mushroom pizza with no extra cheese please\n",
      "Top Decoupled: (PIZZAORDER (NUMBER one ) (SIZE large ) (TOPPING chicken ) (TOPPING mushroom ) (NOT (COMPLEX_TOPPING (QUANTITY extra ) (TOPPING cheese ) ) ) )\n"
     ]
    }
   ],
   "source": [
    "sentence = \"i would like to try one large chicken and mushroom pizza with no extra cheese please\"\n",
    "\n",
    "print(\"Input Order: \" + sentence)\n",
    "\n",
    "# Segment orders\n",
    "isa_words, isa_labels = module1.predict_labels(sentence)\n",
    "orders = segment_orders(isa_words, isa_labels)\n",
    "top_decoupled = ''\n",
    "for order_pair in orders:\n",
    "    order = order_pair[0]\n",
    "    is_pizza = order_pair[1]\n",
    "    parser_words, parser_labels = module2.predict_labels(order)\n",
    "\n",
    "    if is_pizza: id = 0\n",
    "    else: id = 1\n",
    "\n",
    "    top_decoupled += (generate_top_decoupled(order, parser_labels, id) + ' ')\n",
    "\n",
    "print(\"Top Decoupled: \" + top_decoupled[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Index: 1129\n",
      "Input Sentence: can i have a large pizza with red onions bell peppers pepperoni and lettuce\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING red onions ) (TOPPING bell peppers ) (TOPPING pepperoni ) (TOPPING lettuce ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING red onions ) (TOPPING bell ) (TOPPING peppers ) (TOPPING pepperoni ) (TOPPING lettuce ) ) )\n",
      "----------------------------------------------------------------------\n",
      "Row Index: 1176\n",
      "Input Sentence: two small double cheese double pepperoni pizzas please\n",
      "True Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE small ) (COMPLEX_TOPPING (QUANTITY double ) (TOPPING cheese ) ) (COMPLEX_TOPPING (QUANTITY double ) (TOPPING pepperoni ) ) ) )\n",
      "Predicted Output: (ORDER (PIZZAORDER (NUMBER two ) (SIZE small ) (COMPLEX_TOPPING (QUANTITY double ) (TOPPING cheese ) (QUANTITY double ) (TOPPING pepperoni ) ) ) )\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "correct_count = 0\n",
    "i = 0\n",
    "with open(test_data_dir, 'r') as infile:\n",
    "    for line in infile:\n",
    "        instance = json.loads(line)\n",
    "        input_sentence = instance.get(f\"test.SRC\", \"\")\n",
    "        top = instance.get(f\"test.TOP\", \"\")\n",
    "        true_top_decoupled = generate_top_decoupled_from_top(top)\n",
    "\n",
    "        isa_words, isa_labels = module1.predict_labels(input_sentence)\n",
    "        orders = segment_orders(isa_words, isa_labels)\n",
    "        top_decoupled = ''\n",
    "        for order_pair in orders:\n",
    "            order = order_pair[0]\n",
    "            is_pizza = order_pair[1]\n",
    "            parser_words, parser_labels = module2.predict_labels(order)\n",
    "\n",
    "            if is_pizza: id = 0\n",
    "            else: id = 1\n",
    "\n",
    "            top_decoupled += (generate_top_decoupled(order, parser_labels, id) + ' ')\n",
    "        \n",
    "        top_decoupled = \"(ORDER \" + top_decoupled + ')'\n",
    "\n",
    "        if top_decoupled == true_top_decoupled: correct_count += 1\n",
    "        else:\n",
    "            print(f\"Row Index: {i}\")\n",
    "            print(\"Input Sentence: \" + input_sentence)\n",
    "            print(\"True Output: \" + true_top_decoupled)\n",
    "            print(\"Predicted Output: \" + top_decoupled)\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "        \n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985261606484893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_count / i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

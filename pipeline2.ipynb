{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to import all of the necessary dependencies for your model to operate. Both pipeline 1 and 2 should include the following:\n",
    "\n",
    "1. utils.py\n",
    "2. Path to the child model class\n",
    "3. Any extra dependencies unrelated to the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "# (TODO) Rest of the imports (Anyone)\n",
    "from BiLSTM_Module2 import BiLSTM_Module2\n",
    "from LSTM.LSTM import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, store the path to the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) Adjust the path to the test set if needed (Anyone)\n",
    "# Note: This is the ORIGINAL test data, the one that contains test.SRC, test.TOP, etc..\n",
    "# If you don't have it, download it from the repo at https://github.com/amazon-science/pizza-semantic-parsing-dataset/tree/main/data\n",
    "test_data_dir = \"dataset/PIZZA_test.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load modules 1 and 2 using the classes you created. You can change the constructor to take any parameters; just make sure that you classes contain an implementation of the \"predict_labels\" method and takes no extra parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\hassa\\AppData\\Local\\Temp\\ipykernel_15272\\2476852733.py:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  model_path = \"LSTM\\lstm.keras\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model from disk...\n"
     ]
    }
   ],
   "source": [
    "# (TODO) Instantiate module 1 (Hany and Marwan)\n",
    "model_path = \"LSTM\\lstm.keras\"\n",
    "word2vec_path = \"word2vec-google-news-300\"\n",
    "module1 = LSTM(model_path, word2vec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) Instantiate module 2 (Tyson)\n",
    "model_path=\"sequence_labelling_final_model.keras\"\n",
    "module2 = BiLSTM_Module2(model_path,word2vec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! The rest of the code should not be changed. Just run all :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Order: i would like to try one large chicken and mushroom pizza with no extra cheese please\n",
      "Loading word2vec model from disk...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_pizza: \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 17\u001b[0m     top_decoupled \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (generate_top_decoupled(order, parser_labels, \u001b[38;5;28mid\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop Decoupled: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m top_decoupled[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\hassa\\OneDrive\\Desktop\\fall24\\NLP\\Food-Order-Parsing\\utils.py:193\u001b[0m, in \u001b[0;36mgenerate_top_decoupled\u001b[1;34m(sentence, labels, is_pizza_order)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOPPING_INTERMEDIATE\u001b[39m\u001b[38;5;124m\"\u001b[39m: curr_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOPPING\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m curr_label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTYLE_INTERMEDIATE\u001b[39m\u001b[38;5;124m\"\u001b[39m: curr_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTYLE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 193\u001b[0m     output_sentence \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m curr_label \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m curr_element_string \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ) \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    195\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_pizza_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "sentence = \"i would like to try one large chicken and mushroom pizza with no extra cheese please\"\n",
    "\n",
    "print(\"Input Order: \" + sentence)\n",
    "\n",
    "# Segment orders\n",
    "isa_words, isa_labels = module1.predict_labels(sentence)\n",
    "orders = segment_orders(isa_words, isa_labels)\n",
    "top_decoupled = ''\n",
    "for order_pair in orders:\n",
    "    order = order_pair[0]\n",
    "    is_pizza = order_pair[1]\n",
    "    parser_words, parser_labels = module2.predict_labels(order)\n",
    "    print(\"Parser Words: \" + parser_words)\n",
    "    print(\"Parser Labels: \" + parser_labels)\n",
    "    if is_pizza: id = 0\n",
    "    else: id = 1\n",
    "\n",
    "    top_decoupled += (generate_top_decoupled(order, parser_labels, id) + ' ')\n",
    "\n",
    "print(\"Top Decoupled: \" + top_decoupled[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "correct_count = 0\n",
    "i = 0\n",
    "with open(test_data_dir, 'r') as infile:\n",
    "    for line in infile:\n",
    "        instance = json.loads(line)\n",
    "        input_sentence = instance.get(f\"test.SRC\", \"\")\n",
    "        top = instance.get(f\"test.TOP\", \"\")\n",
    "        true_top_decoupled = generate_top_decoupled_from_top(top)\n",
    "\n",
    "        isa_words, isa_labels = module1.predict_labels(input_sentence)\n",
    "        orders = segment_orders(isa_words, isa_labels)\n",
    "        top_decoupled = ''\n",
    "        for order_pair in orders:\n",
    "            order = order_pair[0]\n",
    "            is_pizza = order_pair[1]\n",
    "            parser_words, parser_labels = module2.predict_labels(order)\n",
    "\n",
    "            if is_pizza: id = 0\n",
    "            else: id = 1\n",
    "\n",
    "            top_decoupled += (generate_top_decoupled(order, parser_labels, id) + ' ')\n",
    "        \n",
    "        top_decoupled = \"(ORDER \" + top_decoupled + ')'\n",
    "\n",
    "        if top_decoupled == true_top_decoupled: correct_count += 1\n",
    "        else:\n",
    "            print(f\"Row Index: {i}\")\n",
    "            print(\"Input Sentence: \" + input_sentence)\n",
    "            print(\"True Output: \" + true_top_decoupled)\n",
    "            print(\"Predicted Output: \" + top_decoupled)\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "        \n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count / i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
